{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StyleGAN2 with adaptive discriminator augmentation (ADA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51068,
     "status": "ok",
     "timestamp": 1627827882196,
     "user": {
      "displayName": "Code With Aarohi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDykKNncQS1xHrEv4HD6AW1rHDwSSAtc6R39fACA=s64",
      "userId": "13171438620520647509"
     },
     "user_tz": -330
    },
    "id": "XprG9itJ2uBD",
    "outputId": "2429d705-2acd-4c8d-e174-c590927ef1c4"
   },
   "outputs": [],
   "source": [
    "# Follow NVDIEA System requirement from https://github.com/NVlabs/stylegan2-ada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1627827882196,
     "user": {
      "displayName": "Code With Aarohi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDykKNncQS1xHrEv4HD6AW1rHDwSSAtc6R39fACA=s64",
      "userId": "13171438620520647509"
     },
     "user_tz": -330
    },
    "id": "5ZHjlcQP2xQu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'stylegan2-ada'...\n"
     ]
    }
   ],
   "source": [
    "# Clone the StyleGAN2-ADA repository and go inside the directory\n",
    "\n",
    "!git clone https://github.com/NVlabs/stylegan2-ada.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1627827882196,
     "user": {
      "displayName": "Code With Aarohi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDykKNncQS1xHrEv4HD6AW1rHDwSSAtc6R39fACA=s64",
      "userId": "13171438620520647509"
     },
     "user_tz": -330
    },
    "id": "G2fnTPv826h3",
    "outputId": "5bb4795d-d497-4d03-8f3c-5f9c39a4d3d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ctr-it\\StyleGAN2-ADA-Jupyter\\stylegan2-ada\n"
     ]
    }
   ],
   "source": [
    "cd stylegan2-ada/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1627827882197,
     "user": {
      "displayName": "Code With Aarohi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDykKNncQS1xHrEv4HD6AW1rHDwSSAtc6R39fACA=s64",
      "userId": "13171438620520647509"
     },
     "user_tz": -330
    },
    "id": "TwUvdDCK5LEN"
   },
   "source": [
    "1- Download images from internet and put them in one folder.\n",
    "\n",
    "2- All the images are square and the same size.\n",
    "\n",
    "3- Code needs the dataset to be in .tfrecords format. We first need to convert our dataset to this format. \n",
    "   StyleGAN2-ADA has made a script that makes this conversion easy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45062,
     "status": "ok",
     "timestamp": 1627827952912,
     "user": {
      "displayName": "Code With Aarohi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDykKNncQS1xHrEv4HD6AW1rHDwSSAtc6R39fACA=s64",
      "userId": "13171438620520647509"
     },
     "user_tz": -330
    },
    "id": "sF-qfAkJ-Xwc",
    "outputId": "c4d2761f-1453-4284-a91e-48fc0059d58d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n",
      "(1024, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "path = 'custom_dataset/face_dataset/'\n",
    "\n",
    "\n",
    "im_size = 1024   # Input image resolution must be a power-of-two otherwise you will get error. \n",
    "                 #Pixel resolutions that are powers of 2 (512 x 512, 1024 x 1024, 2048 x 2048, etc).\n",
    "\n",
    "images = []\n",
    "\n",
    "for file in os.listdir(path):\n",
    "        img = cv2.imread(path + '/' + file)  # reading that image as array\n",
    "        img = cv2.resize(img, (im_size, im_size))\n",
    "        print(img.shape)\n",
    "        images.append(img)\n",
    "        # Save the image in Output Folder\n",
    "        cv2.imwrite('custom_dataset/resized_dataset/' + str(file) + '_resized.jpg', img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting images into .tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31072,
     "status": "ok",
     "timestamp": 1627827983975,
     "user": {
      "displayName": "Code With Aarohi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDykKNncQS1xHrEv4HD6AW1rHDwSSAtc6R39fACA=s64",
      "userId": "13171438620520647509"
     },
     "user_tz": -330
    },
    "id": "nAloDQez5vu3",
    "outputId": "a8aeae32-1a0e-44d2-a743-3a779c180e5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\ctr-it\\.conda\\envs\\stylegan2-ada\\lib\\site-packages (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\ctr-it\\.conda\\envs\\stylegan2-ada\\lib\\site-packages (from tqdm) (0.4.4)\n",
      "Loading images from \"custom_dataset/resized_dataset\""
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ctr-it\\.conda\\envs\\styleGAN2-ADA\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ctr-it\\.conda\\envs\\styleGAN2-ADA\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ctr-it\\.conda\\envs\\styleGAN2-ADA\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ctr-it\\.conda\\envs\\styleGAN2-ADA\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ctr-it\\.conda\\envs\\styleGAN2-ADA\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ctr-it\\.conda\\envs\\styleGAN2-ADA\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\ctr-it\\.conda\\envs\\styleGAN2-ADA\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ctr-it\\.conda\\envs\\styleGAN2-ADA\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ctr-it\\.conda\\envs\\styleGAN2-ADA\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ctr-it\\.conda\\envs\\styleGAN2-ADA\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ctr-it\\.conda\\envs\\styleGAN2-ADA\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ctr-it\\.conda\\envs\\styleGAN2-ADA\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating dataset \"custom_dataset/tfrecords_dataset/\"\n",
      "0 / 50\n",
      "10 / 50\n",
      "20 / 50\n",
      "30 / 50\n",
      "40 / 50\n",
      "Flushing data...                        \n",
      "                                        \n",
      "Added 50 images.\n"
     ]
    }
   ],
   "source": [
    "# Below command will create a multi-resolution .tfrecord file in /custom_dataset/tfrecords_dataset/ folder.\n",
    "!pip install tqdm\n",
    "\n",
    "\n",
    "!python dataset_tool.py create_from_images custom_dataset/tfrecords_dataset/ custom_dataset/resized_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 184923,
     "status": "ok",
     "timestamp": 1627828168896,
     "user": {
      "displayName": "Code With Aarohi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDykKNncQS1xHrEv4HD6AW1rHDwSSAtc6R39fACA=s64",
      "userId": "13171438620520647509"
     },
     "user_tz": -330
    },
    "id": "rSPgyXVP-S-T",
    "outputId": "bf11b2e0-87e3-4df8-8c58-80a39ef183ab"
   },
   "outputs": [],
   "source": [
    "#Training StyleGAN2-ADA\n",
    "\n",
    "# snap is how often you want to save the model and sample results\n",
    "# res is what image resolution you want to train on\n",
    "# augpipe is augmentation pipes, such as 'blit', 'geom', 'color', 'filter', 'noise', 'cutout' or combination of these\n",
    "\n",
    "\n",
    "\n",
    "!python train.py --outdir ./results --snap=10 --data=custom_dataset/tfrecords_dataset --augpipe=bgcfnc --res=512 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1627828191883,
     "user": {
      "displayName": "Code With Aarohi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDykKNncQS1xHrEv4HD6AW1rHDwSSAtc6R39fACA=s64",
      "userId": "13171438620520647509"
     },
     "user_tz": -330
    },
    "id": "frkh4DR2Fvxl"
   },
   "outputs": [],
   "source": [
    "# There are many other arguments that you can modify, feel free to check the train.py code to learn more about the arguments.\n",
    "# Once you run the command, it will start training and periodically save the result and the model file (.pkl) based on the snap arguments\n",
    "# that you provided (In this case, every 10kimg). Once you think that the result is good enough or the FID starts to plateau, you can stop training and use the last saved .pkl file.\n",
    "\n",
    "# Once you have the model file you can generate images using this command.\n",
    "\n",
    "#!python generate.py --outdir=out --trunc=0.5 --seeds=600-605 --network={path_to_pkl_model_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Vybo5B_Hv5y"
   },
   "source": [
    "## As We don't have that much memory which can train styleGAN2. So we will download any pretrained model on styleGAN2 and see how to generate images from that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate class conditional CIFAR-10 images (Fig.17 left, Car)\n",
    "#!python generate.py --outdir=out --trunc=1 --seeds=0-35 --class=1 --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/cifar10.pkl\n",
    "\n",
    "!python generate.py --outdir=out1 --trunc=1 --seeds=0-10 --class=1 --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/cifar10.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOS9kZVLODeALxaK26do9k6",
   "collapsed_sections": [],
   "name": "stylegan2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
